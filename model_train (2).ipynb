{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UmW4TF49vpi2"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch --quiet\n",
        "!pip install torchmetrics --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd67CKhuEgcK",
        "outputId": "9192e7e2-fea5-4c9f-dc86-ab2e17209f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlafDGblFMj0",
        "outputId": "60210ec7-510b-4197-cd84-be14dfdf3766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val2017.zip', 'val2017', 'masks']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/maskdata\"\n",
        "print(os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lR3k3xGzFX5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cebb597-abc8-4f3d-abe7-877a418bc8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['val2017.zip', 'val2017', 'masks']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/maskdata/val2017.zip\"\n",
        "extract_path = \"/content/drive/MyDrive/maskdata/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extracted files:\", os.listdir(extract_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5yZyLfbAGXTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8324fd40-8af8-415d-c1f0-dc52eb4284e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000000404249.jpg', '000000319935.jpg', '000000500565.jpg', '000000323709.jpg', '000000376856.jpg', '000000126110.jpg', '000000151051.jpg', '000000218439.jpg', '000000085772.jpg', '000000419653.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/maskdata/val2017\"\n",
        "print(os.listdir(data_path)[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5OK6ry82HMbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48a2335-633e-4e50-e58a-c0326071c9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder found!\n",
            "Total images: 5000\n",
            "First 5 images: ['000000000139.jpg', '000000000285.jpg', '000000000632.jpg', '000000000724.jpg', '000000000776.jpg']\n"
          ]
        }
      ],
      "source": [
        "images_dir = \"/content/drive/MyDrive/maskdata/val2017\"\n",
        "\n",
        "if os.path.exists(images_dir):\n",
        "    print(\"Folder found!\")\n",
        "    image_files = sorted(os.listdir(images_dir))\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(\"First 5 images:\", image_files[:5])\n",
        "else:\n",
        "    print(\"Folder NOT found. Check the path!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eto7GYcGN4C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1a8e82-51b6-46e2-b1a3-b7eb66773da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Masks: 100%|██████████| 50/50 [02:46<00:00,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masks generated for 50 images at /content/drive/MyDrive/maskdata/masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install rembg --quiet\n",
        "!pip install onnxruntime --quiet\n",
        "\n",
        "import os\n",
        "from rembg import remove\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/maskdata/val2017\"\n",
        "masks_dir = \"/content/drive/MyDrive/maskdata/masks\"\n",
        "\n",
        "os.makedirs(masks_dir, exist_ok=True)\n",
        "\n",
        "image_files = sorted(os.listdir(images_dir))[:50]\n",
        "\n",
        "for img_name in tqdm(image_files, desc=\"Generating Masks\"):\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    mask_path = os.path.join(masks_dir, os.path.splitext(img_name)[0] + \".png\")\n",
        "\n",
        "    input_image = Image.open(img_path)\n",
        "    output = remove(input_image)  # Generates mask automatically\n",
        "    output.save(mask_path)\n",
        "\n",
        "print(f\"Masks generated for {len(image_files)} images at {masks_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_lmfJ2MWPf42"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install albumentations --quiet\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jRfKFjofPiYO"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted(os.listdir(images_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.masks_dir, os.path.splitext(self.images[idx])[0] + \".png\")\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))  # grayscale mask\n",
        "\n",
        "        mask = np.where(mask > 0, 1, 0).astype('float32')\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yFbaKLFvP-pV"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "dataset = SegmentationDataset(images_dir=\"/content/drive/MyDrive/maskdata/val2017\",\n",
        "                              masks_dir=\"/content/drive/MyDrive/maskdata/masks\",\n",
        "                              transform=train_transform)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ex_RugVhQC5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f8d5bd-22f1-4f98-9ad2-cb2c183ef9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ylYFLoH9QIsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b2307e-2e78-4431-dc3d-d60fcd23c0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images with masks: 190\n"
          ]
        }
      ],
      "source": [
        "\n",
        "images_dir = \"/content/drive/MyDrive/maskdata/val2017\"\n",
        "masks_dir = \"/content/drive/MyDrive/maskdata/masks\"\n",
        "\n",
        "image_files = sorted([f for f in os.listdir(images_dir)\n",
        "                      if os.path.splitext(f)[0] + \".png\" in os.listdir(masks_dir)])\n",
        "\n",
        "print(f\"Images with masks: {len(image_files)}\")\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, image_files, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        self.images = image_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.masks_dir, os.path.splitext(self.images[idx])[0] + \".png\")\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "        mask = np.where(mask > 0, 1, 0).astype('float32')\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "dataset = SegmentationDataset(images_dir, masks_dir, image_files=image_files, transform=train_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "12Tols2uSCvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9854fd8c-930f-4185-e49e-43512426038d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5414\n",
            "Epoch 2/10, Loss: 0.5390\n",
            "Epoch 3/10, Loss: 0.5302\n",
            "Epoch 4/10, Loss: 0.5161\n",
            "Epoch 5/10, Loss: 0.5032\n",
            "Epoch 6/10, Loss: 0.4884\n",
            "Epoch 7/10, Loss: 0.4998\n",
            "Epoch 8/10, Loss: 0.5020\n",
            "Epoch 9/10, Loss: 0.4869\n",
            "Epoch 10/10, Loss: 0.4951\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}