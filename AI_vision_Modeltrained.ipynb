{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d345204-bf62-46fd-9940-7b08276b3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Training: 100%|██████████████████████████████████████████████████████| 1000/1000 [2:36:13<00:00,  9.37s/it]\n",
      "Epoch 1/5 - Validation: 100%|████████████████████████████████████████████████████████| 250/250 [12:51<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Train Loss: 0.4150 | Val Loss: 0.3339 | Val IoU: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Training: 100%|██████████████████████████████████████████████████████| 1000/1000 [2:33:32<00:00,  9.21s/it]\n",
      "Epoch 2/5 - Validation: 100%|████████████████████████████████████████████████████████| 250/250 [11:17<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Train Loss: 0.3817 | Val Loss: 0.3297 | Val IoU: 0.6960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Training: 100%|██████████████████████████████████████████████████████| 1000/1000 [2:29:55<00:00,  9.00s/it]\n",
      "Epoch 3/5 - Validation: 100%|████████████████████████████████████████████████████████| 250/250 [09:22<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Train Loss: 0.3652 | Val Loss: 0.3319 | Val IoU: 0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Training: 100%|██████████████████████████████████████████████████████| 1000/1000 [2:10:20<00:00,  7.82s/it]\n",
      "Epoch 4/5 - Validation: 100%|████████████████████████████████████████████████████████| 250/250 [11:13<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Train Loss: 0.3559 | Val Loss: 0.3313 | Val IoU: 0.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Training: 100%|██████████████████████████████████████████████████████| 1000/1000 [2:12:16<00:00,  7.94s/it]\n",
      "Epoch 5/5 - Validation: 100%|████████████████████████████████████████████████████████| 250/250 [09:13<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] Train Loss: 0.3508 | Val Loss: 0.3340 | Val IoU: 0.7012\n",
      "✅ Model saved as deeplabv3_hand_segmentation.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "class CocoMaskedDataset(Dataset):\n",
    "    def __init__(self, images_path, annotations_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.coco = COCO(annotations_path)\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.images_path, img_info['file_name'])\n",
    "\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            m = self.coco.annToMask(ann)\n",
    "            mask = np.maximum(mask, m)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        return img, mask.long()\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(p=0.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "images_path = r\"D:\\val2017\\val2017\"\n",
    "annotations_path = r\"D:\\annotations_trainval2017\\annotations\\instances_val2017.json\"\n",
    "\n",
    "dataset = CocoMaskedDataset(images_path, annotations_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "model.classifier[4] = nn.Conv2d(256, 2, kernel_size=1)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)[\"out\"]\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)[\"out\"]\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(model, train_loader, val_loader, num_epochs=5)\n",
    "torch.save(trained_model.state_dict(), \"deeplabv3_hand_segmentation.pth\")\n",
    "print(\"✅ Model saved as deeplabv3_hand_segmentation.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96131559-a255-423f-b725-9e18b906b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "160.55620861053467 MB\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"deeplabv3_hand_segmentation.pth\"))\n",
    "print(os.path.getsize(\"deeplabv3_hand_segmentation.pth\") / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac59de52-84d5-4383-bf14-493dbdace079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in checkpoint: ['backbone.conv1.weight', 'backbone.bn1.weight', 'backbone.bn1.bias', 'backbone.bn1.running_mean', 'backbone.bn1.running_var']\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"deeplabv3_hand_segmentation.pth\")\n",
    "print(\"Keys in checkpoint:\", list(state_dict.keys())[:5])  # print first 5 keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
