{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ae95e8-4e18-4036-9d5b-7484ff60d1d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:270\u001b[0m\n\u001b[0;32m    266\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    268\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 270\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in path/nvidia/lib_folder/lib or path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:253\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    249\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    250\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    252\u001b[0m     )\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Dataset Class\n",
    "# ---------------------------\n",
    "class COCOSegmentationDataset(Dataset):\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        path = img_info['file_name']\n",
    "\n",
    "        # Load image\n",
    "        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
    "\n",
    "        # Load mask\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            mask = np.maximum(mask, self.coco.annToMask(ann))\n",
    "\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            mask = self.transforms(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Define U-Net\n",
    "# ---------------------------\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def CBR(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.enc1 = nn.Sequential(CBR(in_channels, 64), CBR(64, 64))\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(CBR(64, 128), CBR(128, 128))\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3 = nn.Sequential(CBR(128, 256), CBR(256, 256))\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc4 = nn.Sequential(CBR(256, 512), CBR(512, 512))\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.center = nn.Sequential(CBR(512, 1024), CBR(1024, 1024))\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = nn.Sequential(CBR(1024, 512), CBR(512, 512))\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = nn.Sequential(CBR(512, 256), CBR(256, 256))\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(CBR(256, 128), CBR(128, 128))\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(CBR(128, 64), CBR(64, 64))\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        e4 = self.enc4(self.pool3(e3))\n",
    "        center = self.center(self.pool4(e4))\n",
    "\n",
    "        d4 = self.dec4(torch.cat([self.up4(center), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "\n",
    "        return self.final(d1)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Training Setup\n",
    "# ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataDir = r\"C:/Users/rahul/Downloads/coco\"\n",
    "train_dataset = COCOSegmentationDataset(\n",
    "    root=f\"{dataDir}/val2017\",\n",
    "    annFile=f\"{dataDir}/annotations/instances_val2017.json\",\n",
    "    transforms=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = UNet().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training Loop\n",
    "# ---------------------------\n",
    "epochs = 5  # adjust as needed\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "        # Fix shape mismatch\n",
    "        if masks.ndim == 3:   # [B,H,W]\n",
    "            masks = masks.unsqueeze(1)  # [B,1,H,W]\n",
    "        elif masks.ndim == 4 and masks.shape[1] != 1:\n",
    "            masks = masks[:,0:1,:,:]    # take first channel\n",
    "\n",
    "        outputs = model(imgs)           # [B,1,H,W]\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"unet_coco_val2017.pth\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Inference (Test on 1 Image)\n",
    "# ---------------------------\n",
    "model.eval()\n",
    "test_img, test_mask = train_dataset[0]\n",
    "test_inp = test_img.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_mask = torch.sigmoid(model(test_inp))[0][0].cpu().numpy()\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "# Show result\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1); plt.imshow(test_img.permute(1,2,0)); plt.title(\"Original\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,2); plt.imshow(test_mask.squeeze(), cmap=\"gray\"); plt.title(\"Ground Truth Mask\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,3); plt.imshow(pred_mask, cmap=\"gray\"); plt.title(\"Predicted Mask\"); plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a0142-9c3d-4731-a3a5-40aea68ed5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
